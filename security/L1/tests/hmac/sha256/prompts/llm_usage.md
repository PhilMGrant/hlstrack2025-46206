# 大模型辅助使用记录

## 基本信息

- **模型名称**
  - **开源模型**：DeepSeek-V2

- **提供方 / 访问方式**：
  - OpenAI API
- **使用日期**：2025-11-1
- **项目名称**：SHA-256 算子优化

---

## 使用场景 1

### 主要用途
 HLS pragma 指导
### 完整 Prompt 内容
```
你是一个硬件加速器优化专家，特别针对 FPGA/ASIC 高层综合（HLS）和算子（operator）设计，熟悉 Vitis 2024.2 工具链、DPU/加速器部署流程、量化、循环展开、流水线调度、资源约束等。

任务说明：
我当前使用 Vitis 2024.2 工具链，在 FPGA (或 DPU) 上部署一个自定义算子／核（operator），目标是在资源（LUT、FF、BRAM、DSP）、功耗、延迟、吞吐等维度取得更优。你将作为 LLM 助手，帮我从以下几个维度进行优化建议、设计空间探索以及 Vitis 约束/Pragma 参数配置建议。

我将向你提供以下信息：

当前 Vitis 编译后的报告目录E:\hlstrack2025-master\hlstrack2025-master\security\L1\tests\hmac\sha256\hmac_sha256_test.prj\solution1\syn\report\test_hmac_sha256_csynth.rpt和E:\hlstrack2025-master\hlstrack2025-master\security\L1\tests\hmac\sha256\hmac_sha256_test.prj\solution1\sim\report\test_hmac_sha256_cosim.rpt


优化目标：尽可能降低latency和Estimated time，使得两者的乘积越低越好

可变设计空间／参数：xf_security目录下的头文件可以任意修改，主要是hmac.hpp和sha224_256.hpp
```

### 模型输出摘要
1. genPad 函数优化
- 增强并行处理能力，优化字节序转换逻辑
- 改进 XOR 操作，避免使用临时变量
- 优化索引计算，减少计算延迟
- 保持完全展开的循环结构

2. mergeKipad 函数优化
- 添加流水线 pragma (II = 1) 确保每个时钟周期处理一个数据
- 优化延迟约束 (min = 1, max = 2) 提供更实际的性能目标
- 预计算 kipad 字数组，提高并行性
- 优化数据流深度配置

3. mergeKopad 函数优化
- 添加流水线 pragma (II = 1) 和延迟约束
- 预计算 kopad 和 msgHash 字数组
- 改进数据提取和写入模式，减少数据依赖

4. 数据流配置优化
- 减少流深度从 64 到 32，优化资源使用
- 合理分配 FIFO 资源 (BRAM vs SRL)
- 优化 BIND_STORAGE 配置
- 调整延迟约束为更实际的范围

### 人工审核与采纳情况
经过仿真测试，最终采用了第1、2、3条建议，第4条建议未采纳的原因是这条建议关注的资源配置方面，而优化目标是降低总的运行时间。
---

## 使用场景 2

### 主要用途
<!-- 如有多次使用，可复制上述模板继续填写 -->
性能优化建议
### 完整 Prompt 内容
```
[提示词内容]
```
现在报告表明LUT资源使用超出限制，请你对sha224_256进行优化，降低LUT资源的使用。
### 模型输出摘要
<!-- 主要结论 -->
## 快速降低 LUT 使用率的微调方案

### 方案1：调整 SHA256 主循环展开因子（最有效）
__位置__: `sha224_256.hpp` 中的 `LOOP_SHA256_UPDATE_64_ROUNDS` 循环
__预期效果__: 减少 500-800 LUTs

### 方案2：减少数组分区程度
__位置__: `sha224_256.hpp` 中的 W 数组
__预期效果__: 减少 200-400 LUTs

### 方案3：调整 H 数组分区
__位置__: `sha224_256.hpp` 中的 H 数组
__预期效果__: 减少 100-200
### 人工审核与采纳情况
<!-- 采纳情况说明 -->
三个方案都采用了
---


## 使用场景 3

### 主要用途
性能优化建议
### 完整 Prompt 内容
请你针对时序为例问题，对E:\hlstrack2025-master\hlstrack2025-master\security\L1\include\xf_security\sha224_256.hpp进行优化
### 模型输出摘要
### 1. 64轮循环优化
- 使用`PIPELINE II=2`和`UNROLL factor=8`策略
- 修复了算法正确性问题：使用`Kt`变量而不是`K[t]`
- 优化计算链：预计算所有中间值，使用寄存器变量减少关键路径
- 并行更新变量，减少时序路径
### 2. 消息调度生成函数优化
- 使用`PIPELINE II=1`和`UNROLL factor=4`
- 直接使用位操作而不是宏函数调用
- 优化数组移位：使用并行赋值而不是循环
### 3. 预处理函数优化
- 优化字节序转换：并行处理高低32位
- 使用并行位操作减少计算延迟
### 4. 数据流配置优化
- 增加FIFO深度：从64增加到128/256
- 优化资源绑定，使用BRAM资源
### 人工审核与采纳情况
采用了第2、3个建议，第1个建议经过验证，发现这个改动会导致LUT资源超限，而第4个建议对于时序并没有产生优化效果
---


## 总结

### 整体贡献度评估
- 大模型在本项目中的总体贡献占比约 50%
- 主要帮助领域：代码优化
- 人工介入与修正比约50%


### 学习收获
<!-- 通过与大模型交互，您学到了哪些新知识或优化技巧？ -->
1. 时序分析基础
时序Slack概念：理解了正/负Slack的含义，负Slack表示时序违规
关键路径识别：学会了如何定位时序瓶颈模块（如64轮循环、消息调度生成函数）
时序报告解读：掌握了如何从综合报告中提取关键时序信息
2. 数据流优化技巧
FIFO深度优化：理解了数据流深度对时序的影响，学会了合理设置FIFO深度
资源绑定策略：学会了使用`BIND_STORAGE`和`RESOURCE`指令优化资源分配
数据流稳定性：掌握了`STABLE`指令的使用，确保数据流边界稳定性
3. 循环优化技术
循环展开因子：学会了根据时序要求调整UNROLL因子（从16减少到8）
流水线设计：掌握了PIPELINE指令的使用，理解II（Initiation Interval）概念
延迟约束：学会了使用LATENCY约束控制循环延迟
4 算法级优化
字节序转换优化：学会了并行处理高低32位的字节序转换技术
数组移位优化：掌握了使用直接赋值替代循环的数组移位方法
常量数组分区：学会了使用`array_partition`指令提高并行性
---

## 附注

- 请确保填写真实、完整的使用记录
- 如未使用大模型辅助，请在此文件中注明"本项目未使用大模型辅助"
- 评审方将参考此记录了解项目的独立性与创新性
